{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "\n",
    "project_relative_dir = \"../\"\n",
    "sys.path.append(project_relative_dir)\n",
    "\n",
    "from src.openai import MyOpenAI\n",
    "from src.libs.configs import load_shared_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = load_shared_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Info] Used test api key\n"
     ]
    }
   ],
   "source": [
    "C = MyOpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the question\n",
    "question = \"Extract all details from the resume\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = \"\"\"\n",
    "Daniel Wu\n",
    "Toronto, Ontario | danielwu@yahoo.com | (647) 123-4567 | https://www.linkedin.com/in/daniel-wu\n",
    "Professional Experience PlayBoy Inc. Data Scientist\n",
    "● Generated stock market insight for one of the big five banks in Canada by stimulating investment portfolio for 600k+ investors with Python and SQL\n",
    "● Extracted, transformed, and loaded GB level of social media data and stock data on Azure Databricks and MongoDB to provide cleansed data for data analysis\n",
    "● Identified potential crises during data analysis with the current approach and developed a new algorithm in Python to decrease the number of invalid outputs by 30%\n",
    "Smartkids Limited\n",
    "Data Engineer\n",
    "● Developed and maintained ETL pipelines that transformed up to TB levels of weblog data to sustain 4+ machine learning solutions using Python, SQL, and Spark\n",
    "● Automated and optimized the machine learning pipeline that provides monthly insight on 100k+ customers’ churn rate\n",
    "● Built spark applications for the customer data platform with Linux servers and Kubernetes on an enterprise-level cloud platform and distributed file storage cluster and improved retention rate by 9%\n",
    "● Ensured data quality and consistency of 50+ periodically generated datasets from over 1 mil customers using FastAPI and data quality monitoring tools like Great Expectation\n",
    "● Built CI/CD pipelines using Gitlab and wrote unit test modules with Pytest to ship high-quality code in an efficient manner\n",
    "Toll Toll Limited\n",
    "Data Analyst\n",
    "●\n",
    "● Created over 40 structured reports with SQL and analytical software tool JasperReports to monitor day-to-day system performance\n",
    "● Performed R&D and built AI models with Python that reduced plate detection failure by 30%\n",
    "● Ensured transaction accuracy and correctness by generating 30+ unique datasets for the QA\n",
    "tests on system APIs\n",
    "● Aligned data standards and policies of the FFTS with the Government level requirement\n",
    "Change of Denmark\n",
    "Data Scientist\n",
    "● Built and Automated GB-level data pipelines for over 30 e-commerce and social media data with Python, Selenium, and NoSQL databases to achieve competitive monitoring\n",
    "● Developed image classification models with Python and TensorFlow and achieved > 87% accuracy for classification and color/pattern recognition of clothes and shoes\n",
    "● Collaborated with stakeholders and data scientists to understand retailers’ needs and provided actionable insights monthly\n",
    "Education\n",
    "The University of Hong Kong\n",
    "BSc in Mathematics – Computational and Applied Mathematics Stream\n",
    "• Minor in Japanese Language\n",
    "Certificates\n",
    "Microsoft Certified: Azure Data Engineer Associate Microsoft Certified: Azure Data Fundamentals\n",
    "Skills\n",
    "Professional\n",
    "ETL pipeline | Big Data Engineering | Data Governance | Data Science | Machine Learning | Deep Learning | CI/CD pipeline | Web Scraping\n",
    "01/2024 – present\n",
    "09/2022 - 07/2023\n",
    "  Designed and built tables in MySQL databases for the Free Flow Tolling System (FFTS) that\n",
    "05/2021 - 09/2022\n",
    "06/2019 - 05/2021\n",
    "2018\n",
    "11/2023 08/2023\n",
    " handles daily traffic data of tunnels with millions of users\n",
    "       \n",
    "Technical\n",
    "Programming: Python | SQL | Bash | R | Stata | MATLAB\n",
    "Big Data and Distributed Computing: Apache Spark | Apache Hadoop | PySpark | Kubernetes\n",
    "ML and Data Science Libraries: Pandas | Scikit-learn | TensorFlow | PyTorch | Optuna | Matplotlib | NumPy\n",
    "Databases: Oracle | MySQL | MongoDB\n",
    "Deployment: Git | Gitlab Runner | Apache Airflow\n",
    "Languages\n",
    "English | Chinese (Mandarin) | Chinese (Cantonese) | Japanese – JLPT N1\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = C.ask(question, s, output_format=cfg[\"output_formats\"][\"parsing\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse the string into a dictionary\n",
    "output_dict = json.loads(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyspark",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
